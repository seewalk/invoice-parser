# üöÄ AWS S3 Upload Setup Guide - PRODUCTION READY

## ‚úÖ **Implementation Complete!**

Your InvoiceParse.ai now supports **direct S3 file uploads** using the AWS SDK!

---

## üì¶ **What Was Implemented**

### **1. AWS SDK Integration**
- ‚úÖ Installed `@aws-sdk/client-s3` (AWS SDK v3)
- ‚úÖ Installed `@aws-sdk/s3-request-presigner`
- ‚úÖ Added S3Client configuration
- ‚úÖ Implemented PutObjectCommand for uploads

### **2. Smart Upload Flow**
```typescript
1. User selects file
   ‚Üì
2. Generate unique S3 key with timestamp
   ‚Üì
3. Upload file to S3 using AWS SDK
   ‚Üì
4. Get S3 URL (https://bucket.s3.region.amazonaws.com/key)
   ‚Üì
5. Send S3 URL to Lambda API
   ‚Üì
6. Process invoice and display results
```

### **3. Fallback Mechanism**
- ‚úÖ If AWS credentials configured ‚Üí Upload to S3
- ‚úÖ If no credentials ‚Üí Use test image (for demo)
- ‚úÖ Clear error messages for debugging
- ‚úÖ Console logging for transparency

---

## üîß **Setup Instructions**

### **Step 1: Create AWS IAM User**

1. **Go to AWS Console:**
   - Navigate to https://console.aws.amazon.com
   - Sign in to your account

2. **Open IAM Service:**
   - Search for "IAM" in the services search bar
   - Click on "IAM" (Identity and Access Management)

3. **Create New User:**
   - Click "Users" in the left sidebar
   - Click "Create user" button
   - User name: `invoiceparse-s3-uploader`
   - Click "Next"

4. **Set Permissions:**
   - Select "Attach policies directly"
   - Search for "AmazonS3FullAccess" (or create custom policy below)
   - Check the policy
   - Click "Next"

5. **Review and Create:**
   - Review the user details
   - Click "Create user"

### **Step 2: Generate Access Keys**

1. **Open User Details:**
   - Click on the newly created user
   - Go to "Security credentials" tab

2. **Create Access Key:**
   - Scroll down to "Access keys" section
   - Click "Create access key"
   - Select "Application running outside AWS"
   - Click "Next"

3. **Set Description Tag (Optional):**
   - Description: "InvoiceParse.ai frontend S3 uploads"
   - Click "Create access key"

4. **Save Credentials:**
   - ‚ö†Ô∏è **IMPORTANT:** Copy both keys now!
   - Access key ID: `AKIA...` (copy this)
   - Secret access key: `wJal...` (copy this)
   - Click "Download .csv file" for backup
   - ‚ö†Ô∏è You won't be able to see the secret again!

### **Step 3: Configure S3 Bucket**

#### **Option A: Use Existing Bucket**

Your bucket already exists: `invoice-parser-images`

1. **Update CORS Configuration:**
   - Go to S3 Console
   - Click on `invoice-parser-images` bucket
   - Go to "Permissions" tab
   - Scroll to "Cross-origin resource sharing (CORS)"
   - Click "Edit"
   - Paste this configuration:

```json
[
  {
    "AllowedHeaders": [
      "*"
    ],
    "AllowedMethods": [
      "GET",
      "PUT",
      "POST",
      "DELETE",
      "HEAD"
    ],
    "AllowedOrigins": [
      "*"
    ],
    "ExposeHeaders": [
      "ETag"
    ],
    "MaxAgeSeconds": 3000
  }
]
```

2. **Verify Bucket Policy (Optional):**
   - Go to "Permissions" tab
   - Check "Bucket policy"
   - Ensure the bucket allows uploads from your IAM user

#### **Option B: Create New Bucket**

If you need a new bucket:

1. **Create Bucket:**
   - Go to S3 Console
   - Click "Create bucket"
   - Bucket name: `invoice-parser-images` (must be globally unique)
   - Region: `eu-west-2` (London)
   - Uncheck "Block all public access" (if you want public URLs)
   - Click "Create bucket"

2. **Add CORS Configuration:**
   - Follow the CORS steps from Option A above

### **Step 4: Configure Environment Variables**

1. **Copy Example File:**
   ```bash
   cd /home/user/webapp
   cp .env.local.example .env.local
   ```

2. **Edit .env.local:**
   ```bash
   # Open with your editor
   nano .env.local
   # or
   code .env.local
   ```

3. **Add Your AWS Credentials:**
   ```env
   # AWS S3 Configuration
   NEXT_PUBLIC_AWS_REGION=eu-west-2
   NEXT_PUBLIC_AWS_S3_BUCKET=invoice-parser-images
   NEXT_PUBLIC_AWS_ACCESS_KEY_ID=AKIA1234567890EXAMPLE
   NEXT_PUBLIC_AWS_SECRET_ACCESS_KEY=wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY

   # API Configuration
   NEXT_PUBLIC_API_ENDPOINT=https://jm1n4qxu69.execute-api.eu-west-2.amazonaws.com/invoicer-stage/invoiceParser
   ```

4. **Save and Close**

‚ö†Ô∏è **Security Note:** 
- `.env.local` is already in `.gitignore` - your keys won't be committed
- Never share or commit these credentials to Git
- Keep your `.env.local` file secure

### **Step 5: Restart Development Server**

```bash
# Stop the current server (Ctrl+C)
# Then restart:
cd /home/user/webapp
npm run dev
```

---

## üß™ **Testing the Upload**

### **Test Steps:**

1. **Start the application:**
   ```bash
   npm run dev
   ```

2. **Open the parser page:**
   - Navigate to http://localhost:3000/parser

3. **Upload a test invoice:**
   - Drag and drop or click to select a file
   - Click "Process Invoice"

4. **Check the console:**
   ```
   ‚úÖ Good signs:
   - "Starting S3 upload for file: invoice.pdf"
   - "Successfully uploaded to S3: https://..."
   - "Sending to API with S3 URL: ..."
   
   ‚ö†Ô∏è If you see:
   - "AWS credentials not configured, using test image"
   - Check your .env.local file
   - Restart the dev server
   ```

5. **Verify S3 Upload:**
   - Go to AWS S3 Console
   - Open `invoice-parser-images` bucket
   - Check for new file in `uploads/YYYY-MM-DD/` folder
   - You should see your uploaded file!

### **Expected Console Output:**

```javascript
// Success case:
Starting S3 upload for file: my-invoice.pdf
Successfully uploaded to S3: https://invoice-parser-images.s3.eu-west-2.amazonaws.com/uploads/2024-10-17/1729200000000-my_invoice.pdf
Sending to API with S3 URL: { imageUrl: "https://..." }
API Response: {...}
```

---

## üîí **Security Best Practices**

### **1. Use IAM User with Limited Permissions**

Instead of `AmazonS3FullAccess`, create a custom policy:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:PutObjectAcl"
      ],
      "Resource": "arn:aws:s3:::invoice-parser-images/*"
    },
    {
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket"
      ],
      "Resource": "arn:aws:s3:::invoice-parser-images"
    }
  ]
}
```

**To Apply:**
1. Go to IAM Console ‚Üí Policies
2. Click "Create policy"
3. Go to "JSON" tab
4. Paste the policy above
5. Name it: `InvoiceParseS3UploadOnly`
6. Attach to your IAM user

### **2. Environment Variables**

- ‚úÖ **DO:** Use `.env.local` for local development
- ‚úÖ **DO:** Use Vercel/Netlify environment variables for production
- ‚ùå **DON'T:** Commit `.env.local` to Git
- ‚ùå **DON'T:** Share credentials in screenshots or logs

### **3. Rotate Access Keys Regularly**

- Generate new keys every 90 days
- Delete old keys after rotation
- Use AWS IAM Access Analyzer to audit

### **4. Production Considerations**

For production deployments:

1. **Use Backend Proxy (Recommended):**
   - Don't expose AWS credentials in frontend
   - Create a backend API endpoint that generates pre-signed URLs
   - Frontend requests upload URL from your backend
   - Frontend uploads to S3 using pre-signed URL

2. **Alternative: Environment Variables in Hosting Platform**
   - Vercel: Add to Environment Variables in dashboard
   - Netlify: Add to Environment Variables in settings
   - AWS Amplify: Add to Environment Variables

---

## üìä **File Organization in S3**

Your uploaded files are organized like this:

```
invoice-parser-images/
‚îî‚îÄ‚îÄ uploads/
    ‚îú‚îÄ‚îÄ 2024-10-17/
    ‚îÇ   ‚îú‚îÄ‚îÄ 1729200000000-invoice1.pdf
    ‚îÇ   ‚îú‚îÄ‚îÄ 1729200001234-receipt2.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ 1729200002345-bill3.png
    ‚îú‚îÄ‚îÄ 2024-10-18/
    ‚îÇ   ‚îî‚îÄ‚îÄ 1729286400000-invoice4.pdf
    ‚îî‚îÄ‚îÄ 2024-10-19/
        ‚îî‚îÄ‚îÄ ...
```

**Benefits:**
- ‚úÖ Organized by date for easy browsing
- ‚úÖ Unique filenames prevent overwrites
- ‚úÖ Original filename preserved (sanitized)
- ‚úÖ Easy to implement lifecycle policies

---

## üîß **Troubleshooting**

### **Issue: "AWS credentials not configured"**

**Symptom:** Console shows "AWS credentials not configured, using test image"

**Solution:**
1. Check `.env.local` file exists
2. Verify variable names start with `NEXT_PUBLIC_`
3. Restart dev server after creating `.env.local`
4. Check for typos in credential values

```bash
# Verify file exists
ls -la /home/user/webapp/.env.local

# Check content (be careful not to share output!)
cat /home/user/webapp/.env.local

# Restart server
cd /home/user/webapp && npm run dev
```

### **Issue: "Failed to upload to S3: Access Denied"**

**Possible Causes:**
- IAM user doesn't have PutObject permission
- Bucket policy blocks uploads
- Wrong bucket name in config

**Solution:**
1. Verify IAM permissions (see Security Best Practices)
2. Check bucket name matches exactly
3. Verify region is correct
4. Check bucket policy allows uploads

### **Issue: "Failed to upload to S3: Network error"**

**Possible Causes:**
- Wrong region specified
- CORS not configured on bucket
- Firewall blocking AWS

**Solution:**
1. Verify region in .env.local matches bucket region
2. Add CORS configuration to S3 bucket (see Step 3)
3. Check network connection

### **Issue: "CORS error in browser console"**

**Symptom:** Browser shows CORS policy error

**Solution:**
1. Add CORS configuration to S3 bucket
2. Ensure `AllowedOrigins` includes your domain
3. For development, use `"*"` (wildcard)
4. For production, specify exact origins

```json
{
  "AllowedOrigins": [
    "https://your-domain.com",
    "http://localhost:3000"
  ]
}
```

### **Issue: File uploads but API fails**

**Possible Causes:**
- S3 URL not accessible publicly
- Lambda can't access S3 file
- Wrong URL format

**Solution:**
1. Check S3 bucket public access settings
2. Verify Lambda has S3 read permissions
3. Test S3 URL directly in browser
4. Check URL format in console logs

---

## üìà **Monitoring & Costs**

### **S3 Storage Costs (eu-west-2 London):**
- **Storage:** $0.023 per GB/month
- **PUT requests:** $0.005 per 1,000 requests
- **GET requests:** $0.0004 per 1,000 requests
- **Data transfer out:** $0.09 per GB (first 10 TB)

### **Estimated Costs:**

**100 invoices per day (3,000/month):**
- Storage (1MB/invoice): ~3 GB = **$0.07/month**
- PUT requests: 3,000 uploads = **$0.015/month**
- GET requests: 3,000 downloads = **$0.0012/month**
- Data transfer: ~3 GB = **$0.27/month**
- **Total: ~$0.36/month**

**1,000 invoices per day (30,000/month):**
- Storage: ~30 GB = **$0.69/month**
- PUT requests: **$0.15/month**
- GET requests: **$0.012/month**
- Data transfer: ~30 GB = **$2.70/month**
- **Total: ~$3.55/month**

### **CloudWatch Monitoring:**

Set up CloudWatch alarms:
```bash
# Monitor S3 bucket size
# Monitor number of objects
# Monitor request counts
# Set alerts for unusual activity
```

---

## üéØ **Production Deployment**

### **For Vercel:**

1. **Add Environment Variables:**
   - Go to Vercel Dashboard
   - Select your project
   - Go to Settings ‚Üí Environment Variables
   - Add all variables from `.env.local`
   - Save and redeploy

2. **Deploy:**
   ```bash
   vercel --prod
   ```

### **For Netlify:**

1. **Add Environment Variables:**
   - Go to Netlify Dashboard
   - Select your site
   - Go to Site settings ‚Üí Build & deploy ‚Üí Environment
   - Add all variables
   - Trigger new deploy

### **For AWS Amplify:**

1. **Add Environment Variables:**
   - Go to Amplify Console
   - Select your app
   - Go to App settings ‚Üí Environment variables
   - Add all variables
   - Save and redeploy

---

## ‚úÖ **Checklist**

Before going live, ensure:

- [ ] IAM user created with S3 permissions
- [ ] Access keys generated and saved securely
- [ ] S3 bucket configured with CORS
- [ ] `.env.local` created with correct credentials
- [ ] Dev server restarted after adding credentials
- [ ] Test upload successful
- [ ] File appears in S3 bucket
- [ ] API processing works with S3 URL
- [ ] Results display correctly
- [ ] Environment variables added to hosting platform
- [ ] Production deployment tested

---

## üéâ **You're Ready!**

Your InvoiceParse.ai now has **production-ready S3 file uploads**!

### **What Works Now:**

‚úÖ Direct file upload to S3  
‚úÖ Unique timestamped filenames  
‚úÖ Organized folder structure by date  
‚úÖ Automatic S3 URL generation  
‚úÖ API integration with uploaded files  
‚úÖ Fallback to test image for demos  
‚úÖ Comprehensive error handling  
‚úÖ Console logging for debugging  

### **Next Steps:**

1. Set up your AWS credentials (15 minutes)
2. Test with real invoices
3. Deploy to production
4. Monitor S3 usage
5. Implement lifecycle policies (optional)

---

## üìû **Support**

If you encounter issues:

1. Check this guide's Troubleshooting section
2. Review console logs for error messages
3. Verify AWS credentials and permissions
4. Test S3 bucket access directly
5. Check CORS configuration

**Common AWS Resources:**
- S3 Console: https://s3.console.aws.amazon.com
- IAM Console: https://console.aws.amazon.com/iam
- CloudWatch Logs: https://console.aws.amazon.com/cloudwatch

---

**Built with AWS SDK v3 for maximum performance and reliability!** ‚ö°üöÄ
